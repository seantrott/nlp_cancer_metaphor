---
title: "Power Analysis"
output:
  html_document:
    toc: true
    toc_float: true
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load external libraries

```{r}
library(tidyverse)
library(pwr)
library(tictoc)
library(boot)
library(glue)
theme = theme_minimal()
```

# Power Analysis

## Load Clean Data

Created via `clean_data.R`.

```{r}
scale_2sd = function(x) {
  return((x - mean(x, na.rm = T)) / (2 * sd(x, na.rm = T)))
}

trials = read_csv("../pilot_data/clean_pilot.csv", col_types = cols()) %>%
              select(donation, cond_sex, cond_metaphor, age, gender, self_cancer, ff_cancer, english, socioeconomic, education) %>%
              mutate(
              cond_sex = factor(cond_sex, levels = c("male", "female")),
              cond_metaphor = factor(cond_metaphor, levels = c("literal", "battle", "journey")),
              cond_anymet = cond_metaphor %in% c("battle", "journey"),
              
              age.z = scale_2sd(age),
              gender = factor(gender, levels = c("M", "F", "NB")),
              self_cancer = factor(self_cancer, levels = c("Y", "N")),
              ff_cancer = factor(ff_cancer, levels = c("Y", "N")),
              english = factor(english, levels = c("Y", "N")),
              socioeconomic = ordered(socioeconomic, levels = c("<10k", "10-25k", "25-50k", "50-75k", "75-100k", "100-150k", ">150k")),
              education = ordered(education, levels = c("<HS", "HS", "A", "B", "M", "P", "D"))) %>%
  
              drop_na() # lastly, drop all rows that contain NA values
```

Set up a couple helper functions to calculate effect sizes.

```{r}
r.sq = function(mod.base, mod.full) {
  #' Calculate the R-squared value given two nested models
  #' 
  #' The variance explained by a full model beyond that which is explained by the reduced model.
  #' Technically, a difference in sum of squared residuals divided by the base model's sum of squared residuals
  #' Adapted from Larsen & Marx (2018) pg. 566
  
  return((sum(resid(mod.base)^2) - sum(resid(mod.full)^2)) / sum(resid(mod.base)^2))
}
f.sq = function(mod.null, mod.base, mod.full) {
  #' Calculate the f-squared effect size from two R-squared values
  #'
  #' Adapted from Cohen (1988) pg. 409
  
  R2.base = r.sq(mod.null, mod.base)
  R2.full = r.sq(mod.null, mod.full)
  
  return((R2.full - R2.base) / (1 - R2.full))
}
```

## Effect Size Calculation

See the previous helper functions in action. Here, we calculate the effect size of `cond_anymet` (Any Metaphor).

```{r}
# first, build a null model
m0 = lm(donation ~ 1, data = trials)

# then build a reduced model
m1 = lm(donation ~ cond_sex + gender + education + socioeconomic + age.z + self_cancer + ff_cancer, data = trials)

# then build a full model
m2 = lm(donation ~ cond_sex + gender + education + socioeconomic + age.z + self_cancer + ff_cancer + cond_anymet, data = trials)

glue("Reduced model R-squared: {round(r.sq(m0, m1), 4)}") # compute the R-squared of the reduced model
glue("Full model R-squared: {round(r.sq(m0, m2), 4)}") # compute the R-squared of the full model

# These values of R-squared are what you get if you examine the summary() function for each

# Lastly, compute the f-squared effect size
glue("f-squared ES: {round(f.sq(m0, m1, m2), 5)}")
```

## Bootstrap

We also bootstrap BCa confidence intervals over the effect size. Note that there might be issues interpreting this, since effect size shouldn't necessarily depend on effect size, yet the confidence intervals will reflect the uncertainty in the data.

```{r}
f.sq.est = function(data, ixs) {
  #' Estimate f-squared from a new set of models given a subset of the data
  #' 
  #' Used for the bootstrap of the intervals
  #' Some subsets will not include sufficiently filled out factors and thus will throw an error; we discard these samples
  
  tryCatch({
    m0 = lm(donation ~ 1, data = data[ixs, ])
    m1 = lm(donation ~ cond_sex + gender + education + socioeconomic + age.z + self_cancer + ff_cancer, data = data[ixs, ])
    m2 = lm(donation ~ cond_sex + gender + education + socioeconomic + age.z + self_cancer + ff_cancer + cond_anymet, data = data[ixs, ])
    
    return(f.sq(m0, m1, m2))
  },
  error = function(c) {return(NA)})
}
```

Estimate the effect size. This takes about 2 minutes on a 4-core Mac.

```{r}
tic()
bs.f.sq = boot(trials, f.sq.est, R = 20060, parallel="multicore", ncpus = 3)
toc()
```

Plot the sampling distributions. Display the estimate as well, which happens to have very little bias.

```{r}
plot(bs.f.sq)
bs.f.sq
```

Under 50 of the resamples from the bootstrap fail, which is accounted for an we still have over 20,000 resamples.

```{r}
sum(is.na(bs.f.sq$t))
```

Calulate and display the BCa CIs.

```{r}
ci.f.sq = boot.ci(bs.f.sq, type="bca", conf = 0.95)
ci.f.sq
```

Determine the number of covariates in the model.

```{r}
num_covs = length(coef(m2)) - 1
num_covs
```

## Hypothesis Power

Calculate the total sample size necessary for 90% power given the effect size found above. This work is motivated by Cohen (1988).

```{r}
power = pwr.f2.test(u = num_covs, v = NULL, f2 = bs.f.sq$t0, power = 0.9)
power
```

## Calculate power for other suggested hypotheses

Create a function to calculate f-squared from a more general model form than used previously.

```{r}
gen.f.sq.est = function(data, ixs) {
  tryCatch({
    m0 = lm(donation ~ 1, data = data[ixs, ])
    m1 = lm(donation ~ cond_sex + gender + education + socioeconomic + age.z + self_cancer + ff_cancer, data = data[ixs, ])
    m2 = lm(donation ~ cond_sex + gender + education + socioeconomic + age.z + self_cancer + ff_cancer + cond_metaphor, data = data[ixs, ])
    
    return(f.sq(m0, m1, m2))
  },
  error = function(c) {return(NA)})
}
```

First, we would like to determine the effect size of a  Journey against Literal effect. Using this effect size, we calculate the power of the test given the sample size determined for the main hypothesis above.

```{r}
# subset to include only campaigns that used Journey or were literal
trials.subset = trials[trials$cond_metaphor != "battle", ]

tic()
bs.f.sq.jl = boot(trials.subset, gen.f.sq.est, R = 20060, parallel="multicore", ncpus = 3)
toc()

bs.f.sq.jl
sum(is.na(bs.f.sq.jl$t))
```

Battle against Literal effect

```{r}
# subset to include only campaigns that used Battle or were literal
trials.subset = trials[trials$cond_metaphor != "journey", ]

tic()
bs.f.sq.bl = boot(trials.subset, gen.f.sq.est, R = 20060, parallel="multicore", ncpus = 3)
toc()

bs.f.sq.bl
sum(is.na(bs.f.sq.bl$t))
```

Battle against Journey effect

```{r}
# subset to include only campaigns that used Journey or Battle
trials.subset = trials[trials$cond_metaphor != "literal", ]

tic()
bs.f.sq.bj = boot(trials.subset, gen.f.sq.est, R = 20060, parallel="multicore", ncpus = 3)
toc()

bs.f.sq.bj
sum(is.na(bs.f.sq.bj$t))
```

Power of these last three tests given the sample size of the main hypothesis

```{r}
pwr.f2.test(u = num_covs, v = ceiling(power$v), f2 = bs.f.sq.jl$t0, power = NULL) # journey against literal
pwr.f2.test(u = num_covs, v = ceiling(power$v), f2 = bs.f.sq.bl$t0, power = NULL) # battle against literal
pwr.f2.test(u = num_covs, v = ceiling(power$v), f2 = bs.f.sq.bj$t0, power = NULL) # journey against battle
```
