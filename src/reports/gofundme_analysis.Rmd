---
title: "Metaphor Analysis in Kickstarter Campaigns"
output:
  html_document:
    toc: yes
  pdf_document:
    toc: yes
---

**Sean Trott and Alex Liebscher**

# Introduction

We have several dependent variables which we would like to model as accurately as possible to determine the variables which contribute most to their outcomes. In particular, we care about the effect of the metaphor (or lack thereof) in each project. We first explore the data a little, and then begin a series of model comparisons for the dependent variables. Comparing models gives transparency to the contributions of each variable toward the target.

1. Do projects that use metaphor generally receive better funding? How does using metaphor (and which type of metaphor family) influence campaign success, number of backers, and mean donation?

2. Does higher metaphor productivity change the result?

3. How can we characterize projects by the metaphors they employ?

4. Within a metaphor family, are there canonical instantiations of a metaphor? (E.g. "fight battle"). Or even if productivity is low generally, are instantiations varied?

5. How does metaphor vary with other interesting features, such as project description length, goal amount, project type/category, or cancer type?

# Related Work

Hendricks, R. K., Demjén, Z., Semino, E., & Boroditsky, L. (2018). Emotional Implications of Metaphor: Consequences of Metaphor Framing for Mindset about Cancer. Metaphor and Symbol, 33(4), 267–279. https://doi.org/10.1080/10926488.2018.1549835

Semino, E., Demjén, Z., Demmen, J., Koller, V., Payne, S., Hardie, A., & Rayson, P. (2017). The online use of Violence and Journey metaphors by patients with cancer, as compared with health professionals: a mixed methods study. BMJ Supportive & Palliative Care, 7(1), 60–66. https://doi.org/10.1136/bmjspcare-2014-000785


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load Data

Total projects and columns available

```{r}
dat = read.csv('../../data/processed/gofundme_projects.csv')
labs = read.csv('../../data/processed/labeled.csv')
dat = dat[dat$id %in% labs$project_id, ]

nrow(dat)
colnames(dat)
```

```{r}
library(lme4)
library(tidyverse)
```

# Data Exploration

### Projects per year

```{r}
ggplot(dat) + geom_bar(aes(year), stat="count") + labs(title="Number of projects per year")
```

There are very few projects before 2013, and so for simplicity's sake and to simplify the model just a tad, we remove 2012 and before.

```{r}
dat = dat[dat$year >= 2013, ]
```

### Projects per month

```{r}
dat$month <- factor(dat$month)

dat %>%
  ggplot() + labs(title="Counts in Months") +
  geom_bar(aes(month)) +
  scale_x_discrete(labels = c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"))
```

Interestingly, there are a ton of January projects. This might have to do with scraping the site which lists projects chronologically.

### Projects per day of the week

```{r}
dat$day_of_week <- factor(dat$day_of_week)

dat %>%
  ggplot() + labs(title="Counts in Days of the Week") +
  geom_bar(aes(day_of_week)) +
  scale_x_discrete(labels = c("Mon", "Tue", "Wed", "Thur", "Fri", "Sat", "Sun"))
```

Fairly uniform, with slightly more projects being launched in the middle of the week (Thursday) anda bit fewer being launched on the weekend (notably Saturday).

```{r}
chisq.test(table(dat$day_of_week))
```

There is significant difference between the observed and the expected number of projects launched each day of the week. Therefore import to include this variable in the models. 

### Projects from the US

```{r}
ggplot(dat) + geom_bar(aes(x=factor(from_US)), stat="count") + labs(x="From US", title="Number of projects from US")
```

Most projects are US based. Reduce model complexity by restricting to the US then. Moreover, worrying about non-US projects means doing currency conversion and other strange things.

```{r}
dat <- dat[dat$from_US == 1, ]
```

### Project goals, text lengths, and cancer types

We scale/z-score the continuous variables according to how we wish to interpret the coefficients of the model. From Andrew Gelman: "Standardizing puts things on an approximately common scale .... (Standarize for) comparing coefficients for different predictors within a model". Binary and categorical variables are left as is.

```{r}
dat$goal_sc <- scale(dat$goal)

dat %>%
  ggplot() + labs(title="Goal Amount Distribution") +
  geom_density(aes(goal))

dat$duration_float_sc = scale(dat$duration_float)

dat %>%
  ggplot() + labs(title="Duration Distribution") +
  geom_density(aes(duration_float))

dat$text_length_words_sc <- scale(dat$text_length_words)

dat %>%
  ggplot() + labs(title="Text Length Distribution") +
  geom_density(aes(text_length_words))

dat$photos_sc <- scale(dat$photos)

dat %>%
  ggplot() + labs(title="Photos Distribution") +
  geom_density(aes(photos))

dat$updates_sc <- scale(dat$updates)

dat %>%
  ggplot() + labs(title="Updates Distribution") +
  geom_density(aes(updates))

dat$shares_sc <- scale(dat$shares)

dat %>%
  ggplot() + labs(title="FB Shares Distribution") +
  geom_density(aes(shares))

dat$comments_sc <- scale(dat$comments)

dat %>%
  ggplot() + labs(title="Comments Distribution") +
  geom_density(aes(comments))

dat$friends_sc <- scale(dat$friends)

dat %>%
  ggplot() + labs(title="FB Friends Distribution") +
  geom_density(aes(friends))

dat %>%
  ggplot() + labs(title="Cancer Type Counts") +
  geom_bar(aes(x=cancer_type)) +
  coord_flip()
```

```{r}
na.omit(labs) %>% ggplot() + geom_bar(aes(x=reorder(keyword, keyword, function(x)-length(x)), fill=metaphorical)) + coord_flip() + theme_minimal()
```

Taking a look at differences in instantiation across metaphor family.

```{r}
ggplot() + 
  geom_density(aes(dat[dat$only_journey == T, "first_instantiation"]), fill=rgb(1,0.5,0.5), alpha=0.3,) +
  geom_density(aes(dat[dat$only_battle == T, "first_instantiation"]), fill=rgb(0.5,0.5,1), alpha=0.3) +
  geom_density(aes(dat[dat$dom_battle == T, "first_instantiation"]), fill=rgb(0,0,1), alpha=0.3) +
  geom_density(aes(dat[dat$dom_journey == T, "first_instantiation"]), fill=rgb(1,0,0), alpha=0.3) +
  labs(x="Instantiation Position")
```

### Project metaphors

We break down each project into how the metaphor families are distributed within the project text.

`no_metaphor` : Does the project lack metaphorical instances of keywords?
`any_metaphor` : Does the project contain any metaphors at all?
`dom_journey` : Is the journey metaphor family the dominant family?
`dom_battle` : Is the battle metaphor family the dominant family?
`only_journey` : Is the journey metaphor family the only family present?
`only_battle` : Is the battle metaphor family the only family present?
`both_metaphor` : Are both metaphor families present?

```{r}
dat$no_metaphor = dat$battle_salience == 0.0 & dat$journey_salience == 0.0
dat$any_metaphor = as.logical(1 - dat$no_metaphor)
dat$dom_journey = dat$journey_salience > dat$battle_salience
dat$dom_battle = dat$battle_salience > dat$journey_salience
dat$only_journey = dat$journey_salience > 0 & dat$battle_salience == 0.0
dat$only_battle = dat$journey_salience == 0.0 & dat$battle_salience > 0
dat$both_metaphor = dat$battle_salience > 0.0 & dat$journey_salience > 0.0

dat$battle_prod = scale(dat$battle_prod)
dat$journey_prod = scale(dat$journey_prod)
dat$battle_salience = scale(dat$battle_salience)
dat$journey_salience = scale(dat$journey_salience)

metaphor_counts = data.frame(counts = colSums(dat[, c("no_metaphor", "any_metaphor", "dom_journey", "dom_battle", "only_journey", "only_battle", "both_metaphor")]))

ggplot() + labs(x="Metaphor Type", y="Count", title="Count in Metaphor Types") +
  geom_bar(stat="identity", aes(x=row.names(metaphor_counts), y=metaphor_counts$counts))
```

Good resources:
https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html
https://ase.tufts.edu/gsc/gradresources/guidetomixedmodelsinr/mixed%20model%20guide.html

# Primary Analyses

We are interested in the effect that metaphor presence has on the funding status, the number of backers, and the mean donation of a project.

**DV**: status, backers, mean donation

**IV**: Goal amount, text length words, duration, year, month, day of the week, photos, updates, FB shares, FB friends, cancer type

Many of these covariates explained in:

 - Astrauskaitė, I., & Paškevičius, A. (2018). An analysis of crowdfunded projects: KPI’s to success. Entrepreneurship and Sustainability Issues, 6(1), 23–24. https://doi.org/10.9770/jesi.2018.6.1(2)

We perform drop1 model comparisons for each regression. The least significant (highest p-value) variable is removed in the subsequent model.

Various sources were used to determine what should be a random effect and what should be fixed, and how to model interactions and correlations between variables, including:

 - Data Analysis Using Regression and Multilevel/Hierarchical Models (Gelman and Hill, 2006)
 - Interactions in Generalized Linear Models: Theoretical Issues and an Application to Personal Vote-Earning Attributes (Tsai and Gill, 2013)
 - Should I Use Fixed or Random Effects? (Clark and Linzer, 2012)
 - Random effects structure for confirmatory hypothesis testing: Keep it maximal (Barr et al., 2013)
 - https://stats.stackexchange.com/questions/13166/rs-lmer-cheat-sheet
 - https://stats.stackexchange.com/questions/4700/what-is-the-difference-between-fixed-effect-random-effect-and-mixed-effect-mode/151800#151800
 - https://rlbarter.github.io/Practical-Statistics/2017/03/03/fixed-mixed-and-random-effects/
 - https://stats.stackexchange.com/questions/323273/what-to-do-with-random-effects-correlation-that-equals-1-or-1
 - Fitting linear mixed-effects models using lme4 (Bates et al., 2014)
 - http://www.leg.ufpr.br/~eder/Variance%20Components.pdf

# Status

```{r}
nrow(dat)
```

In total, we have N=5223 IID samples to work with.

```{r}
dat %>%
  ggplot() + labs(title="Goal Amount Distribution") + guides(color=guide_legend(title="Status")) +
  geom_density(aes(goal, color=fct_recode(factor(status), "Successful"="1", "Failed"="0"))) +
  theme_minimal()

dat %>%
  ggplot() + labs(title="Duration Distribution") + guides(color=guide_legend(title="Status")) +
  geom_density(aes(duration_float, color=fct_recode(factor(status), "Successful"="1", "Failed"="0"))) +
  theme_minimal()

dat %>%
  ggplot() + labs(title="Text Length Distribution") + guides(color=guide_legend(title="Status")) +
  geom_density(aes(text_length_words, color=fct_recode(factor(status), "Successful"="1", "Failed"="0"))) +
  theme_minimal()

dat %>%
  ggplot() + labs(title="Photos Distribution") + guides(color=guide_legend(title="Status")) +
  geom_density(aes(photos, color=fct_recode(factor(status), "Successful"="1", "Failed"="0"))) +
  theme_minimal()

dat %>%
  ggplot() + labs(title="Updates Distribution") + guides(color=guide_legend(title="Status")) +
  geom_density(aes(updates, color=fct_recode(factor(status), "Successful"="1", "Failed"="0"))) +
  theme_minimal()

dat %>%
  ggplot() + labs(title="FB Friends Distribution") + guides(color=guide_legend(title="Status")) +
  geom_density(aes(friends, color=fct_recode(factor(status), "Successful"="1", "Failed"="0"))) +
  theme_minimal()

dat %>%
  ggplot() + labs(title="Comments Distribution") + guides(color=guide_legend(title="Status")) +
  geom_density(aes(comments, color=fct_recode(factor(status), "Successful"="1", "Failed"="0"))) +
  theme_minimal()

dat %>%
  ggplot() + labs(title="FB Shares Distribution") + guides(color=guide_legend(title="Status")) +
  geom_density(aes(shares, color=fct_recode(factor(status), "Successful"="1", "Failed"="0"))) +
  theme_minimal()

dat %>%
  ggplot() + labs(title="Cancer Type Counts") + guides(fill=guide_legend(title="Status")) +
  geom_bar(aes(x=cancer_type, fill=fct_recode(factor(status), "Successful"="1", "Failed"="0")), position="dodge") +
  theme(axis.text.x=element_text(angle = 60, hjust=1))

```

Removed all random variabes except year because they didn't help explain any variance in the data beyond what the residuals could capture. Year is a reasonable random effect as well (see Variance Components, Searle et al 2006)

Nesting and Chi2 differences:
https://www.psychologie.uzh.ch/dam/jcr:ffffffff-b371-2797-0000-00000fda8f29/chisquare_diff_en.pdf

## Model status

```{r}
status.formula = status ~ shares_sc + friends_sc + updates_sc + photos_sc + goal_sc + text_length_words_sc + duration_float_sc + cancer_type + month + day_of_week + (1|year)

status.mod = glmer(status.formula, data = dat, family = "binomial")

drop1(status.mod, test="Chisq")
```

```{r}
status.formula = update(status.formula,  ~ . - day_of_week)
drop1(glmer(status.formula, data = dat, family = "binomial"), test="Chisq")
```

```{r}
status.formula = update(status.formula,  ~ . - month)
drop1(glmer(status.formula, data = dat, family = "binomial"), test="Chisq")
```

```{r}
status.formula = update(status.formula,  ~ . - text_length_words_sc)
drop1(glmer(status.formula, data = dat, family = "binomial"), test="Chisq")
```

```{r}
status.formula = update(status.formula,  ~ . - friends_sc)
drop1(glmer(status.formula, data = dat, family = "binomial"), test="Chisq")
```

The final base model before adding metaphor variables:

```{r}
status.mod = glmer(status.formula, data = dat, family = "binomial")
summary(status.mod)
```

## Add metaphors

See https://stats.stackexchange.com/questions/77313/why-cant-i-match-glmer-family-binomial-output-with-manual-implementation-of-g and https://www.rdocumentation.org/packages/lme4/versions/1.1-19/topics/glmer

```{r}
status.refit = function(formula, key) {
  new.mod = glmer(formula, data = dat, family = "binomial")
  print(anova(new.mod, status.mod, test="Chisq"))
  print(fixef(new.mod)[key])
}
```

```{r}
addMetaphors = function(formula, refit) {
  refit(update(formula,  ~ . + no_metaphor), "no_metaphorTRUE")
  refit(update(formula,  ~ . + any_metaphor), "any_metaphorTRUE")
  refit(update(formula,  ~ . + both_metaphor), "both_metaphorTRUE")
  refit(update(formula,  ~ . + dom_journey), "dom_journeyTRUE")
  refit(update(formula,  ~ . + dom_journey + journey_prod), "journey_prod")
  refit(update(formula,  ~ . + dom_battle), "dom_battleTRUE")
  refit(update(formula,  ~ . + dom_battle + battle_prod), "battle_prod")
  refit(update(formula,  ~ . + only_battle), "only_battleTRUE")
  refit(update(formula,  ~ . + only_battle + battle_prod), "battle_prod")
  refit(update(formula,  ~ . + only_journey), "only_journeyTRUE")
  refit(update(formula,  ~ . + only_journey + journey_prod), "journey_prod")
  refit(update(formula,  ~ . + scale(battle_salience)), "scale(battle_salience)")
  refit(update(formula,  ~ . + scale(journey_salience)), "scale(journey_salience)")
}
```

```{r status metaphor}
addMetaphors(status.formula, status.refit)
```

```{r}
# inst.formula = status ~ shares_sc + updates_sc + photos_sc + goal_sc + duration_float_sc + cancer_type + (1|year)
# inst.status.mod = glmer(inst.formula, data = dat[dat$only_journey, ], family = "binomial")
# inst.mod = glmer(update(inst.formula, ~ . + first_instantiation), data = dat[dat$only_journey, ], family = "binomial")
# anova(inst.mod, inst.status.mod, test="Chisq")
# fixef(inst.mod)["first_instantiation"]
```

Trying out a Bayesian regression for status. Not really developed yet and not fully Bayesian, but just playing around. Instead of comparing a bunch of models again, just took the structure of the fit glmer model and used that. Results are what one would expect but shed a little more light on how each varaible effects the model.

```{r}
library(brms)
```

Again, just reusing the glmer model for simplicity.

```{r}
m = brm(status ~ shares_sc + updates_sc + photos_sc + goal_sc + duration_float_sc + cancer_type + (1 | year), data = dat, family = "bernoulli", cores = 4)
```

```{r}
summary(m)
```


```{r}
marginal_effects(m)
```


# Number of Backers

```{r}
library(glmmTMB)
```

```{r}
nrow(dat[dat$backers > 1200, ])
ggplot() + labs(x="Number of Backers", title="Number of Backers Density") +
  geom_density(aes(dat$backers[dat$backers < 1200]))
```

We limit to 1200 because removing the outliers leaves us with a nicely shaped distribution.

```{r}
dat.b <- dat[dat$backers < 1200, ]
```

Run a quick data dispersion test (see Rice 1995):

```{r}
s = na.omit(dat.b)
pchisq(2 * sum(dat.b$backers * log(dat.b$backers / mean(dat.b$backers))), length(dat.b$backers) - 1, lower.tail = F)
```

H0: The data are fit well by a Poisson Distribution
H1: Poisson fails to fit the data well

The Poisson distribution obviously does not fit the data well since p approx 0. Let's use a NegBin instead, which can account for differences in the mean and variance.

```{r}
dat.b %>%
  ggplot(aes(goal, backers)) + labs(title="Goal Amount Distribution") +
  geom_point(aes(alpha=0.1)) +
  theme_minimal()

dat.b %>%
  ggplot(aes(duration_float, backers)) + labs(title="Duration Distribution") +
  geom_point(aes(alpha=0.1)) +
  theme_minimal()

dat.b %>%
  ggplot(aes(text_length_words, backers)) + labs(title="Text Length Distribution") +
  geom_point(aes(alpha=0.1)) +
  theme_minimal()

dat.b %>%
  ggplot(aes(photos, backers)) + labs(title="Photos Distribution") +
  geom_point(aes(alpha=0.1)) +
  theme_minimal()

dat.b %>%
  ggplot(aes(updates, backers)) + labs(title="Updates Distribution") +
  geom_point(aes(alpha=0.1)) + 
  theme_minimal()

dat.b %>%
  ggplot(aes(friends, backers)) + labs(title="FB Friends Distribution") +
  geom_point(aes(alpha=0.1)) + 
  theme_minimal()

dat.b %>%
  ggplot(aes(shares, backers)) + labs(title="FB Shares Distribution") +
  geom_point(aes(alpha=0.1)) + 
  theme_minimal()

dat.b %>%
  ggplot(aes(cancer_type, backers)) + labs(title="Cancer Types") +
  geom_boxplot() +
  theme_minimal() +
  theme(axis.text.x=element_text(angle = 60, hjust=1))
```

## Model backers

It might be the case that a quasi-Poisson model fits better, see:
https://digitalcommons.unl.edu/cgi/viewcontent.cgi?article=1141&context=usdeptcommercepub

Negative binomial has a lower residual deviance than quasi-poisson. Therefore we use NegBin.

Inherently, the number of backers must be > 0, thus we model using a truncated NegBin fit.

```{r}
backers.formula = backers ~ shares_sc + friends_sc + updates_sc + photos_sc + goal_sc + text_length_words_sc + duration_float_sc + cancer_type + month + day_of_week + (1|year)

backers.mod = glmmTMB(backers.formula, data = dat.b, family = "truncated_nbinom2")
drop1(backers.mod, test="Chisq")
```

```{r}
backers.formula = update(backers.formula,  ~ . - day_of_week)
drop1(glmmTMB(backers.formula, data = dat.b, family = "truncated_nbinom2"), test="Chisq")
```

```{r}
backers.formula = update(backers.formula,  ~ . - friends_sc)
drop1(glmmTMB(backers.formula, data = dat.b, family = "truncated_nbinom2"), test="Chisq")
```


```{r}
backers.formula = update(backers.formula,  ~ . - month)
drop1(glmmTMB(backers.formula, data = dat.b, family = "truncated_nbinom2"), test="Chisq")
```

```{r}
backers.mod = glmmTMB(backers.formula, data = dat.b, family = "truncated_nbinom2")
summary(backers.mod)
```

## Add metaphors

```{r backers metaphor}
backers.refit = function(formula, key) {
  new.mod = glmmTMB(formula, data = dat.b, family = "truncated_nbinom2")
  print(anova(new.mod, backers.mod, test="Chisq"))
  print(fixef(new.mod)$cond[key])
}

addMetaphors(backers.formula, backers.refit)
```

OLD, IGNORE:
On average, not having metaphors present lowers the expected value of log(backers) by 17.3%. When battle metaphors are dominant, the expected value of log(backers) increases by 13.1%. When battle metaphors are dominant, then an additional unit of battle productivity increases the expected value of log(backers) by 1.1%. When there are only battle metaphors present, we see an increase of 12.9%. Unit increases in battle salience lead to 7.2% increases in log(backers) expected value, and similarly, a unit increase in journey salience leads to a 3.8% increase.

# Mean Donation

```{r}
dat %>%
  ggplot() + labs(title="Mean Donation Density") +
  geom_density(aes(mean_donation))

dat.m = dat[dat$mean_donation < 500, ]

dat.m %>%
  ggplot() + labs(title="Mean Donation Density") +
  geom_density(aes(mean_donation))

dat.m %>%
  ggplot() + geom_qq(aes(sample=mean_donation+1), distribution = qexp) + geom_qq_line(aes(sample=mean_donation+1), distribution = qexp)
```

```{r}
dat.m %>%
  ggplot(aes(goal, mean_donation)) + labs(title="Goal Amount Distribution") +
  geom_point(aes(alpha=0.1)) +
  theme_minimal()

dat.m %>%
  ggplot(aes(duration_float, mean_donation)) + labs(title="Duration Distribution") +
  geom_point(aes(alpha=0.1)) +
  theme_minimal()

dat.m %>%
  ggplot(aes(text_length_words, mean_donation)) + labs(title="Text Length Distribution") +
  geom_point(aes(alpha=0.1)) +
  theme_minimal()

dat.m %>%
  ggplot(aes(photos, mean_donation)) + labs(title="Photos Distribution") +
  geom_point(aes(alpha=0.1)) +
  theme_minimal()

dat.m %>%
  ggplot(aes(updates, mean_donation)) + labs(title="Updates Distribution") +
  geom_point(aes(alpha=0.1)) + 
  theme_minimal()

dat.m %>%
  ggplot(aes(friends, mean_donation)) + labs(title="FB Friends Distribution") +
  geom_point(aes(alpha=0.1)) + 
  theme_minimal()

dat.m %>%
  ggplot(aes(shares, mean_donation)) + labs(title="FB Shares Distribution") +
  geom_point(aes(alpha=0.1)) + 
  theme_minimal()

dat.m %>%
  ggplot(aes(cancer_type, mean_donation)) + labs(title="Cancer Types") +
  geom_boxplot() +
  theme_minimal() +
  theme(axis.text.x=element_text(angle = 60, hjust=1))
```

 - https://stats.stackexchange.com/questions/142013/correct-glmer-distribution-family-and-link-for-a-continuous-zero-inflated-data-s
 
The data look like a Gamma, so we model with Gamma and a log link (see above answer for reason). It might be nice 

Ideally, I could run a distributional test and confirm (or reject) this intuition.

## Model mean donation

```{r}
mean.formula = mean_donation ~ shares_sc + friends_sc + updates_sc + photos_sc + goal_sc + text_length_words_sc + duration_float_sc + cancer_type + month + day_of_week + (1|year)

mean.mod = glmer(mean.formula, data = dat.m, family = Gamma(link = "log"))
drop1(mean.mod, test="Chisq")
```

```{r}
mean.formula = update(mean.formula,  ~ . - duration_float_sc)
drop1(glmer(mean.formula, data = dat.m, family = Gamma(link = "log")), test="Chisq")
```

```{r}
mean.formula = update(mean.formula,  ~ . - day_of_week)
drop1(glmer(mean.formula, data = dat.m, family = Gamma(link = "log")), test="Chisq")
```


```{r}
mean.formula = update(mean.formula,  ~ . - photos_sc)
drop1(glmer(mean.formula, data = dat.m, family = Gamma(link = "log")), test="Chisq")
```

```{r}
mean.formula = update(mean.formula,  ~ . - month)
drop1(glmer(mean.formula, data = dat.m, family = Gamma(link = "log")), test="Chisq")
```

```{r}
mean.mod = glmer(mean.formula, data = dat.m, family = Gamma(link = "log"))
summary(mean.mod)
```

lmer produces AIC of 54710, with shares_sc + friends_sc + updates_sc + goal_sc + text_length_words_sc + cancer_type + (1 | year)

## Add metaphors

```{r mean donation metaphor}
mean.refit = function(formula, key) {
  new.mod = glmer(formula, data = dat.m, family = Gamma(link = "log"))
  print(anova(new.mod, mean.mod, test="Chisq"))
  print(fixef(new.mod)[key])
}

addMetaphors(mean.formula, mean.refit)
```

Mean donation but with lmer

```{r}
# mean2.formula = mean_donation+1 ~ shares_sc + friends_sc + updates_sc + photos_sc + goal_sc + text_length_words_sc + duration_float_sc + cancer_type + month + day_of_week + (1|year)
# 
# mean2.mod = lmer(formula, data = dat.m)
# 
# mean2.formula = update(mean2.formula,  ~ . - month)
# new.mod = lmer(mean2.formula, data = dat.m)
# anova(new.mod, mean2.mod, test="Chisq")
# mean2.mod = new.mod
# 
# mean2.formula = update(mean2.formula,  ~ . - day_of_week)
# new.mod = lmer(mean2.formula, data = dat.m)
# anova(new.mod, mean2.mod, test="Chisq")
# mean2.mod = new.mod
# 
# mean2.formula = update(mean2.formula,  ~ . - duration_float_sc)
# new.mod = lmer(mean2.formula, data = dat.m)
# anova(new.mod, mean2.mod, test="Chisq")
# mean2.mod = new.mod
# 
# mean2.formula = update(mean2.formula,  ~ . - photos_sc)
# new.mod = lmer(mean2.formula, data = dat.m)
# anova(new.mod, mean2.mod, test="Chisq")
# mean2.mod = new.mod
```


```{r}
# summary(mean2.mod)
# AIC(mean2.mod)
```

```{r}
# formula.temp = update(mean2.formula,  ~ . + no_metaphor)
# new.mod = lmer(formula.temp, data = dat.m)
# anova(new.mod, mean2.mod, test="Chisq")
# fixef(new.mod)["no_metaphorTRUE"]
# 
# formula.temp = update(mean2.formula,  ~ . + any_metaphor)
# new.mod = lmer(formula.temp, data = dat.m)
# anova(new.mod, mean2.mod, test="Chisq")
# fixef(new.mod)["any_metaphorTRUE"]
# 
# formula.temp = update(mean2.formula,  ~ . + dom_journey)
# new.mod = lmer(formula.temp, data = dat.m)
# anova(new.mod, mean2.mod, test="Chisq")
# fixef(new.mod)["dom_journeyTRUE"]
# 
# formula.temp = update(mean2.formula,  ~ . + dom_journey + journey_prod)
# new.mod.prod = lmer(formula.temp, data = dat.m)
# anova(new.mod.prod, new.mod, test="Chisq")
# fixef(new.mod.prod)["journey_prod"]
# 
# formula.temp = update(mean2.formula,  ~ . + dom_battle)
# new.mod = lmer(formula.temp, data = dat.m)
# anova(new.mod, mean2.mod, test="Chisq")
# fixef(new.mod)["dom_battleTRUE"]
# 
# formula.temp = update(mean2.formula,  ~ . + dom_battle + battle_prod)
# new.mod.prod = lmer(formula.temp, data = dat.m)
# anova(new.mod.prod, new.mod, test="Chisq")
# fixef(new.mod.prod)["battle_prod"]
# 
# formula.temp = update(mean2.formula,  ~ . + only_battle)
# new.mod = lmer(formula.temp, data = dat.m)
# anova(new.mod, mean2.mod, test="Chisq")
# fixef(new.mod)["only_battleTRUE"]
# 
# formula.temp = update(mean2.formula,  ~ . + only_battle + battle_prod)
# new.mod.prod = lmer(formula.temp, data = dat.m)
# anova(new.mod.prod, new.mod, test="Chisq")
# fixef(new.mod.prod)["battle_prod"]
# 
# formula.temp = update(mean2.formula,  ~ . + only_journey)
# new.mod = lmer(formula.temp, data = dat.m)
# anova(new.mod, mean2.mod, test="Chisq")
# fixef(new.mod)["only_journeyTRUE"]
# 
# formula.temp = update(mean2.formula,  ~ . + only_journey + journey_prod)
# new.mod.prod = lmer(formula.temp, data = dat.m)
# anova(new.mod.prod, new.mod, test="Chisq")
# fixef(new.mod.prod)["journey_prod"]
# 
# formula.temp = update(mean2.formula,  ~ . + scale(battle_salience))
# new.mod = lmer(formula.temp, data = dat.m)
# anova(new.mod, mean2.mod, test="Chisq")
# fixef(new.mod)["scale(battle_salience)"]
# 
# formula.temp = update(mean2.formula,  ~ . + scale(journey_salience))
# new.mod = lmer(formula.temp, data = dat.m)
# anova(new.mod, mean2.mod, test="Chisq")
# fixef(new.mod)["scale(journey_salience)"]
```